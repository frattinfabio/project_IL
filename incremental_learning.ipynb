{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "progettone_final_version.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XcSDvttzaqQ",
        "colab_type": "text"
      },
      "source": [
        "# **Incremental learning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6D41xr8Plomg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1V-_wcygJDNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cloning the github repo with all the necessary code\n",
        "if not os.path.isdir(\"./project_IL\"):\n",
        "  !git clone https://github.com/frattinfabio/project_IL.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQCRO5dclvoZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from project_IL.model.IncrementalLearner import IncrementalLearner\n",
        "from project_IL.params import get_params\n",
        "from project_IL.data_handler.data_utils import load_data\n",
        "from project_IL.classifiers.classifiers_utils import evaluate_incremental"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_cMfDBZzVHs",
        "colab_type": "text"
      },
      "source": [
        "## **Defining parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWd_291fplIX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NUM_CLASSES = 100\n",
        "NUM_GROUPS = 10\n",
        "CLASSES_PER_GROUP = NUM_CLASSES // NUM_GROUPS\n",
        "SPLITTING_SEED = 15\n",
        "APPROACH = \"COSINE\" # possible values: [\"FINETUNING\", \"LWF\", \"ICARL\", \"VARIATION\", \"COSINE\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHzhZ1R0a-JD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get the pre-defined params according to the decided approach\n",
        "# modify those params for a different learning behaviour\n",
        "# ex: modify approach_params[\"distillation_loss\"] for a different distillation behaviour\n",
        "train_params, approach_params = get_params(APPROACH) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G707_wmZziH0",
        "colab_type": "text"
      },
      "source": [
        "## **Main module**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GHVYnxPaZN7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "il = IncrementalLearner(NUM_CLASSES, NUM_GROUPS, SPLITTING_SEED, approach_params, train_params,)\n",
        "classifier = approach_params[\"classifier\"]\n",
        "\n",
        "new_classes_accuracies = []\n",
        "old_classes_accuracies = []\n",
        "overall_accuracies = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIyrZ2T6bcvj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for _ in range(il.num_groups):\n",
        "\n",
        "  # going into the next incremental step\n",
        "  il.step()\n",
        "  # loading the new data\n",
        "  train_dataloader, new_test_dataloader, old_test_dataloader = load_data(il.current_step, il.splitter.labels_split, il.train_params, il.exemplars)\n",
        "  # updating the networks (main + old and ft for distillation if required)\n",
        "  il.update_nets()\n",
        "  # train the ft-net if using the variation approach\n",
        "  if approach_params[\"use_variation\"] and il.current_step > 0:\n",
        "    train_dataloader_no_exemplars, _, _ = load_data(il.current_step, il.splitter.labels_split, il.train_params, None)\n",
        "    il.train_ft(train_dataloader_no_exemplars)\n",
        "  # train the main network\n",
        "  il.train(train_dataloader)\n",
        "  # updating the classifier with the new data and the new state of the network\n",
        "  classifier.update(il.current_step, il.net, train_dataloader)\n",
        "  # updating the exemplars set according to approach_params[\"exemplar_selection\"]\n",
        "  if approach_params[\"use_exemplars\"]:\n",
        "    il.update_exemplars()\n",
        "\n",
        "  # evaluating the network both on old and new classes\n",
        "  print(\"Classifying...\")\n",
        "  accuracies = evaluate_incremental(new_test_dataloader, old_test_dataloader, classifier)\n",
        "  new_classes_accuracies.append(accuracies[\"new\"])\n",
        "  old_classes_accuracies.append(accuracies[\"old\"])\n",
        "  overall_accuracies.append(accuracies[\"overall\"])\n",
        "  print(f\"Accuracies after having learned {il.n_known_classes} classes:\")\n",
        "  print(f\"- current:\\t{accuracies['new']:.3f}\")\n",
        "  if il.current_step > 0:\n",
        "    print(f\"- old:\\t{accuracies['old']:.3f}\")\n",
        "    print(f\"- overall:\\t{accuracies['overall']:.3f}\")\n",
        "  print(\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tbVK2dRe8qWI"
      },
      "source": [
        "## **Results visualization**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5yb3PGGX8qWK",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "results_df = pd.DataFrame(\n",
        "    data = zip(range(CLASSES_PER_GROUP,NUM_CLASSES+CLASSES_PER_GROUP,CLASSES_PER_GROUP), new_classes_accuracies, old_classes_accuracies, overall_accuracies),\n",
        "    columns = [\"num_classes_learned\", \"new_classes_accuracy\", \"old_classes_accuracy\", \"overall_accuracy\"])\n",
        "results_df.set_index(\"num_classes_learned\")\n",
        "\n",
        "results_df.plot(x = \"num_classes_learned\", marker = 'o', figsize = (14,8))\n",
        "plt.xlim(0,NUM_CLASSES+CLASSES_PER_GROUP)\n",
        "plt.ylim(0,1)\n",
        "plt.grid(True, axis = 'y')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YqfiX2hp8qWM",
        "colab": {}
      },
      "source": [
        "results_df.to_csv(\"./accuracy_results.csv\", index = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lnp3Dk6T8qWO",
        "colab": {}
      },
      "source": [
        "def get_predictions(classifier, test_dataloader): \n",
        "  predictions = []\n",
        "  ground_truth = []\n",
        "  for images, labels in test_dataloader:\n",
        "    images = images.cuda()\n",
        "    labels = labels.cuda()\n",
        "    preds = classifier.classify(images)\n",
        "    for label, pred in zip(labels.data, preds):\n",
        "      ground_truth.append(label.item())\n",
        "      predictions.append(pred.item())\n",
        "\n",
        "  return ground_truth, predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gVMMGPSg8qWQ",
        "colab": {}
      },
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from project_IL.data_handler.SubCIFAR import SubCIFAR\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "\n",
        "# plotting the predictions heatmap\n",
        "full_test_dataset = SubCIFAR(labels_split = il.splitter.labels_split, labels = list(range(NUM_CLASSES)), train = False, transform = train_params[\"test_transform\"])\n",
        "full_test_dataloader =  DataLoader(full_test_dataset, batch_size = train_params[\"BATCH_SIZE\"], num_workers = 4)\n",
        "truth, pred = get_predictions(classifier, full_test_dataloader)\n",
        "conf = confusion_matrix(truth, pred)\n",
        "\n",
        "fig, ax = plt.subplots(figsize = (13,10))\n",
        "sns.heatmap(np.log(conf+1), cmap=\"coolwarm\", ax = ax)\n",
        "plt.xlabel(\"Predicted class\")\n",
        "plt.ylabel(\"True Class\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yg0t5y4JZ37X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.savetxt(\"preds.csv\", pred, delimiter = \",\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWtQMX5u7og4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# histogram of number of predictions per class\n",
        "fig, ax = plt.subplots(figsize = (16, 8))\n",
        "labels, counts = np.unique(pred, return_counts=True)\n",
        "plt.bar(labels, counts, align='center')\n",
        "plt.xlabel(\"class\")\n",
        "plt.ylabel(\"num_predictions\")\n",
        "plt.hlines(y = 100, xmin = -0.5, xmax = 100-0.5, colors = 'r', label = \"right number of predictions\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8psZkVf3pLfp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "# histogram of number of predictions per group\n",
        "group_pred = [math.floor(p/CLASSES_PER_GROUP) for p in pred]\n",
        "fig, ax = plt.subplots(figsize = (16, 8))\n",
        "labels, counts = np.unique(group_pred, return_counts=True)\n",
        "plt.bar(labels, counts, align='center', width = 0.6)\n",
        "plt.xlabel(\"group\")\n",
        "plt.ylabel(\"num_predictions\")\n",
        "plt.hlines(y = 100*CLASSES_PER_GROUP, xmin = -0.5, xmax = NUM_GROUPS-0.5, colors = 'r', label = \"right number of predictions\")\n",
        "plt.gca().set_xticks(labels)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EkNY67Nl8qWZ",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "report = classification_report(truth, pred, zero_division = 0, output_dict = True)\n",
        "report_df = pd.DataFrame(report).transpose()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uMMxXzCo8qWc",
        "colab": {}
      },
      "source": [
        "report_df.to_csv(\"./classification_report.csv\", index = False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}